{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "# We need to set the following parameters:\n",
        "\n",
        "'''\n",
        "- gamma (edge penalty),\n",
        "- gamma_c (clique param),\n",
        "- alpha (learning rate),\n",
        "- beta (momentum),\n",
        "- T (number of interations to converge per initialization), and\n",
        "- eta (explration parameter)\n",
        "'''"
      ],
      "metadata": {
        "id": "ZOGVsoezEB7y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "78e2959a-af0f-44e5-9a82-ad49612e6c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n- gamma (edge penalty), \\n- gamma_c (clique param), \\n- alpha (learning rate), \\n- beta (momentum), \\n- T (number of interations to converge per initialization), and \\n- eta (explration parameter)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This Code does a quick tuning of the hyper-parameters of pCQO-MIS to ensure feaisble solutions.\n",
        "\n",
        "Note that to obtain the best results from pCQO, we need more tuning.\n",
        "\n",
        "## Steps:\n",
        "- Select $\\gamma'$. Below, we use $\\gamma' = 1$.\n",
        "- From our Theorem, we have $\\gamma > 1 +\\gamma'\\Delta(G')$ where $\\Delta(G')$ is the maximum degree of the compliment graph $G'$. As such, here, we set $\\gamma = 2+\\Delta(G')$.\n",
        "- Select $\\beta$. Below, we use $\\beta = 0.9$.\n",
        "- Iterate over a set of step sizes. For example, $\\alpha \\in \\{0.0001, 0.0005, 0.0001, 0.005, 0.01, 0.05\\}$.\n",
        "- At each $\\alpha$, we use multiple initilizations. We use a while loop to record the number of steps needed for convergence in under a limit or $T$. Below, we use $T=500$.\n",
        "- Log the best MIS, $T$, and number of times we get a feasible solution over the number of initializations.\n",
        "- Then, select the smallest $T$ based on the largest MIS and the ratio of obtaining solutions.\n",
        "- Set $\\eta \\geq 2.5$ for the variance of the Gaussian distribution used to obtain the initializations of the next batch. This is not needed here.\n",
        "\n",
        "\n",
        "In what follow, we provide an example. This was tested on random ER graphs with $n$ up to 1000, and $p\\in [0.01,0.9]$ where $p$ is the probability of edge creation. This $p$ is also an indication of the graph density. $d$-regular graphs (where $d$ is the degree) were also tested."
      ],
      "metadata": {
        "id": "1HguN_59NUUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of the output of this notebook is:\n",
        "\n",
        "++++++++++++ FINAL ++++++++++++\n",
        "\n",
        "gamma   =  [149]\n",
        "\n",
        "gamma_c =  [1]\n",
        "\n",
        "alpha   =  [0.05]\n",
        "\n",
        "beta    =  [0.8]\n",
        "\n",
        "T       =  [np.int64(73)]\n",
        "\n",
        "++++++++++++++++++++++++++++++\n",
        "\n",
        "In our pcqmis.cpp, these correspond to:\n",
        "\n",
        "++++++++++++ FINAL ++++++++++++\n",
        "\n",
        "gamma   =  GAMMA\n",
        "\n",
        "gamma_c =  GAMMA_PRIME\n",
        "\n",
        "alpha   =  LEARNING_RATE\n",
        "\n",
        "beta    =  MOMENTUM\n",
        "\n",
        "T       =  NUM_ITERATIONS_PER_BATCH\n",
        "\n",
        "++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "UvQ21jGjg5R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph\n",
        "\n",
        "\n",
        "######## ER ###########\n",
        "n = 300\n",
        "p = 0.6\n",
        "G = nx.gnp_random_graph(n, p, seed=0)\n",
        "\n",
        "\n",
        "# ######## d reg ###########\n",
        "# n = 1000\n",
        "# d = 10\n",
        "# G = nx.random_regular_graph(d, n)\n",
        "\n",
        "\n",
        "# compliment graph:\n",
        "complement_G = nx.complement(G)\n",
        "\n",
        "num_components = nx.number_connected_components(G)\n",
        "\n",
        "print(\"Number of connected components:\", num_components)\n",
        "\n",
        "if num_components == 1:\n",
        "    print(\"Graph has one connected component.\")\n",
        "else:\n",
        "    print(\"Graph has more than one connected component.\")\n",
        "\n",
        "### Obtain the A_G matrix\n",
        "\n",
        "adjacency_matrix = nx.adjacency_matrix(G)\n",
        "adjacency_matrix_dense = adjacency_matrix.todense()\n",
        "adjacency_matrix_tensor = torch.tensor(adjacency_matrix_dense, dtype=torch.float32)\n",
        "\n",
        "### Obtain the A_G_hat matrix\n",
        "\n",
        "adjacency_matrix_comp = nx.adjacency_matrix(complement_G)\n",
        "adjacency_matrix_dense_comp = adjacency_matrix_comp.todense()\n",
        "adjacency_matrix_tensor_comp = torch.tensor(adjacency_matrix_dense_comp, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "OIClYyYPE8Ar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "522b033f-1782-4843-f540-ff2e7c4f33fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of connected components: 1\n",
            "Graph has one connected component.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Efficient MIS Checking 2: Directly check if a binarized X is a maximal IS without checking whether it is an IS first...\n",
        "\n",
        "def MIS_checker_efficient_3(X_torch, adjacency_matrix_tensor, adjacency_matrix_tensor_comp):\n",
        "  n = X_torch.shape[0]\n",
        "  # binarized X\n",
        "  X_torch_binarized = X_torch.bool().float()\n",
        "  # if for some gradient update, we are still at the boundary, then we have maximal IS\n",
        "  X_torch_binarized_update = X_torch_binarized - 0.1*(-torch.ones(n) + (n*adjacency_matrix_tensor)@X_torch_binarized)\n",
        "  # Projection to [0,1]\n",
        "  X_torch_binarized_update[X_torch_binarized_update>=1] =1\n",
        "  X_torch_binarized_update[X_torch_binarized_update<=0] =0\n",
        "  if torch.equal(X_torch_binarized, X_torch_binarized_update):\n",
        "    # we have a maximal IS:\n",
        "    MIS = torch.nonzero(X_torch_binarized).squeeze()\n",
        "    # Exit the function with True\n",
        "    return True, MIS\n",
        "  # If not a maximal IS, Exit the function with False\n",
        "  return False, None"
      ],
      "metadata": {
        "id": "gF707N9mhhlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Here, we set gamma, gamma', and beta.\n",
        "\n",
        "gamma_c = 1\n",
        "degrees_c = dict(complement_G.degree())\n",
        "max_degree = max(degrees_c.values())\n",
        "gamma = 2 + max_degree\n",
        "beta = 0.8"
      ],
      "metadata": {
        "id": "wWlViAGBM30z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Define the alpha set to try\n",
        "\n",
        "alpha_set = [0.000001, 0.000005,0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]"
      ],
      "metadata": {
        "id": "7AIwLKoLEDjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### optimization loop using MGD to obtain T\n",
        "\n",
        "\n",
        "def opt_loop_MGD(seed, adjacency_matrix_tensor, adjacency_matrix_tensor_comp,gamma, gamma_c, alpha, beta):\n",
        "  n = adjacency_matrix_tensor.shape[0]\n",
        "  torch.manual_seed(seed)\n",
        "  input_tensor = torch.rand(n)\n",
        "  input_velocity = torch.zeros_like(input_tensor)\n",
        "\n",
        "  Checker,MIS = MIS_checker_efficient_3(input_tensor, adjacency_matrix_tensor, adjacency_matrix_tensor_comp)\n",
        "  iteration_T = 0\n",
        "  while Checker == False:\n",
        "\n",
        "      iteration_T += 1\n",
        "\n",
        "      # Compute the gradient\n",
        "      gradient = -torch.ones(n) + (gamma*adjacency_matrix_tensor - gamma_c*adjacency_matrix_tensor_comp)@input_tensor\n",
        "\n",
        "      input_velocity = beta*input_velocity + alpha*gradient\n",
        "\n",
        "      input_tensor = torch.clamp(input_tensor - input_velocity, 0, 1)\n",
        "\n",
        "      Checker,MIS = MIS_checker_efficient_3(input_tensor, adjacency_matrix_tensor, adjacency_matrix_tensor_comp)\n",
        "\n",
        "      if Checker:\n",
        "        print(iteration_T, Checker, len(MIS))\n",
        "        break\n",
        "\n",
        "      if iteration_T > 500:\n",
        "        iteration_T = 0\n",
        "        MIS = [0]\n",
        "        break\n",
        "\n",
        "  return [iteration_T, Checker, len(MIS)]\n",
        "\n"
      ],
      "metadata": {
        "id": "2FqHAp5wg944"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "\n",
        "number_of_initializations = 5\n",
        "\n",
        "T_and_MIS_per_alpha = {}\n",
        "\n",
        "for alpha in alpha_set:\n",
        "  print(\"+++++++ We are at alpha = \", [alpha])\n",
        "  MGD_MIS=[]\n",
        "  MGD_iter=[]\n",
        "  T_and_MIS_per_alpha[alpha] = []\n",
        "  ctr = 0\n",
        "  for seed in range(number_of_initializations):\n",
        "    print(\"We are at seed = \", [seed])\n",
        "\n",
        "    temp = opt_loop_MGD(seed, adjacency_matrix_tensor, adjacency_matrix_tensor_comp, gamma, gamma_c, alpha, beta)\n",
        "    if temp[2] > 1:\n",
        "      ctr += 1\n",
        "    MGD_MIS.append(temp[2])\n",
        "    MGD_iter.append(temp[0])\n",
        "\n",
        "  # Here, we log the avg T over seeds, max T over seeds, avg MIS over seeds, mas MIS over seeds, and percentage of obtaining solutions (number of times we got a sol over the number of inits we solved)\n",
        "  T_and_MIS_per_alpha[alpha] = [np.mean(MGD_iter), np.max(MGD_iter), np.mean(MGD_MIS), np.max(MGD_MIS), ctr/number_of_initializations]\n",
        "  print('Mean MIS size', np.mean(MGD_MIS))\n",
        "  print('Mean T', np.mean(MGD_iter))\n",
        "\n",
        "#print('T to select', np.max(MGD_iter))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GanxXMgXmxin",
        "outputId": "541f9eae-0616-4a48-958b-3da7989bad37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+++++++ We are at alpha =  [1e-06]\n",
            "We are at seed =  [0]\n",
            "We are at seed =  [1]\n",
            "We are at seed =  [2]\n",
            "We are at seed =  [3]\n",
            "We are at seed =  [4]\n",
            "Mean MIS size 1.0\n",
            "Mean T 0.0\n",
            "+++++++ We are at alpha =  [5e-06]\n",
            "We are at seed =  [0]\n",
            "We are at seed =  [1]\n",
            "We are at seed =  [2]\n",
            "We are at seed =  [3]\n",
            "We are at seed =  [4]\n",
            "Mean MIS size 1.0\n",
            "Mean T 0.0\n",
            "+++++++ We are at alpha =  [1e-05]\n",
            "We are at seed =  [0]\n",
            "469 True 8\n",
            "We are at seed =  [1]\n",
            "469 True 8\n",
            "We are at seed =  [2]\n",
            "488 True 8\n",
            "We are at seed =  [3]\n",
            "391 True 10\n",
            "We are at seed =  [4]\n",
            "Mean MIS size 7.0\n",
            "Mean T 363.4\n",
            "+++++++ We are at alpha =  [5e-05]\n",
            "We are at seed =  [0]\n",
            "177 True 7\n",
            "We are at seed =  [1]\n",
            "251 True 7\n",
            "We are at seed =  [2]\n",
            "188 True 8\n",
            "We are at seed =  [3]\n",
            "244 True 6\n",
            "We are at seed =  [4]\n",
            "154 True 7\n",
            "Mean MIS size 7.0\n",
            "Mean T 202.8\n",
            "+++++++ We are at alpha =  [0.0001]\n",
            "We are at seed =  [0]\n",
            "163 True 6\n",
            "We are at seed =  [1]\n",
            "110 True 7\n",
            "We are at seed =  [2]\n",
            "145 True 6\n",
            "We are at seed =  [3]\n",
            "94 True 8\n",
            "We are at seed =  [4]\n",
            "97 True 7\n",
            "Mean MIS size 6.8\n",
            "Mean T 121.8\n",
            "+++++++ We are at alpha =  [0.0005]\n",
            "We are at seed =  [0]\n",
            "63 True 7\n",
            "We are at seed =  [1]\n",
            "70 True 8\n",
            "We are at seed =  [2]\n",
            "69 True 8\n",
            "We are at seed =  [3]\n",
            "99 True 8\n",
            "We are at seed =  [4]\n",
            "65 True 7\n",
            "Mean MIS size 7.6\n",
            "Mean T 73.2\n",
            "+++++++ We are at alpha =  [0.001]\n",
            "We are at seed =  [0]\n",
            "52 True 6\n",
            "We are at seed =  [1]\n",
            "66 True 8\n",
            "We are at seed =  [2]\n",
            "71 True 6\n",
            "We are at seed =  [3]\n",
            "64 True 7\n",
            "We are at seed =  [4]\n",
            "62 True 7\n",
            "Mean MIS size 6.8\n",
            "Mean T 63.0\n",
            "+++++++ We are at alpha =  [0.005]\n",
            "We are at seed =  [0]\n",
            "47 True 8\n",
            "We are at seed =  [1]\n",
            "59 True 8\n",
            "We are at seed =  [2]\n",
            "43 True 7\n",
            "We are at seed =  [3]\n",
            "46 True 7\n",
            "We are at seed =  [4]\n",
            "57 True 8\n",
            "Mean MIS size 7.6\n",
            "Mean T 50.4\n",
            "+++++++ We are at alpha =  [0.01]\n",
            "We are at seed =  [0]\n",
            "47 True 6\n",
            "We are at seed =  [1]\n",
            "70 True 7\n",
            "We are at seed =  [2]\n",
            "45 True 7\n",
            "We are at seed =  [3]\n",
            "45 True 6\n",
            "We are at seed =  [4]\n",
            "54 True 8\n",
            "Mean MIS size 6.8\n",
            "Mean T 52.2\n",
            "+++++++ We are at alpha =  [0.05]\n",
            "We are at seed =  [0]\n",
            "55 True 9\n",
            "We are at seed =  [1]\n",
            "73 True 8\n",
            "We are at seed =  [2]\n",
            "51 True 7\n",
            "We are at seed =  [3]\n",
            "47 True 7\n",
            "We are at seed =  [4]\n",
            "58 True 8\n",
            "Mean MIS size 7.8\n",
            "Mean T 56.8\n",
            "+++++++ We are at alpha =  [0.1]\n",
            "We are at seed =  [0]\n",
            "58 True 7\n",
            "We are at seed =  [1]\n",
            "80 True 7\n",
            "We are at seed =  [2]\n",
            "53 True 7\n",
            "We are at seed =  [3]\n",
            "50 True 8\n",
            "We are at seed =  [4]\n",
            "54 True 8\n",
            "Mean MIS size 7.4\n",
            "Mean T 59.0\n",
            "+++++++ We are at alpha =  [0.5]\n",
            "We are at seed =  [0]\n",
            "72 True 8\n",
            "We are at seed =  [1]\n",
            "109 True 8\n",
            "We are at seed =  [2]\n",
            "70 True 7\n",
            "We are at seed =  [3]\n",
            "We are at seed =  [4]\n",
            "67 True 8\n",
            "Mean MIS size 6.4\n",
            "Mean T 63.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# final evaluation:\n",
        "\n",
        "# We need to check the number of times we obtained a solution with the limit of T out of the number of seeds\n",
        "\n",
        "# The following dictionary log:\n",
        "\"\"\"\n",
        "avg T over seeds,\n",
        "max T over seeds,\n",
        "avg MIS over seeds,\n",
        "max MIS over seeds,\n",
        "and percentage of obtaining solutions (number of times we got a sol over the number of inits we solved)\n",
        "\n",
        "Criteria:\n",
        "- Select the smallest T based on the largest MIS and the ratio of obtaining solutions.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# First: filter out the ones where the ratio is not 1 (i.e., the selection of the parameters returned a solution for all the initilizations):\n",
        "\n",
        "T_and_MIS_per_alpha_filtered = {key: value for key, value in T_and_MIS_per_alpha.items() if value[4] == 1}\n",
        "\n",
        "# Second: select alpha (which is the key of this dict) based on the largest avg MIS (3rd entry of the dict):\n",
        "\n",
        "alpha_selected = max(T_and_MIS_per_alpha_filtered, key=lambda x: T_and_MIS_per_alpha_filtered[x][2])\n",
        "\n",
        "# Third: select T as the max T of the alpha_selected\n",
        "\n",
        "T_selected = T_and_MIS_per_alpha_filtered[alpha_selected][1]\n",
        "\n",
        "print('++++++++++++ FINAL ++++++++++++')\n",
        "\n",
        "print(\"gamma   = \", [gamma])\n",
        "print(\"gamma_c = \", [gamma_c])\n",
        "print(\"alpha   = \", [alpha_selected])\n",
        "print(\"beta    = \", [beta])\n",
        "print(\"T       = \", [T_selected])\n",
        "\n",
        "print('++++++++++++++++++++++++++++++')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdyPyRYtGJAP",
        "outputId": "826773ef-20cc-458c-db94-e6554a5bda5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++ FINAL ++++++++++++\n",
            "gamma   =  [149]\n",
            "gamma_c =  [1]\n",
            "alpha   =  [0.05]\n",
            "beta    =  [0.8]\n",
            "T       =  [np.int64(73)]\n",
            "++++++++++++++++++++++++++++++\n"
          ]
        }
      ]
    }
  ]
}